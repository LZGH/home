import builtwith
import pandas
import builtwith
totalCount = '100abc'
 totalCount = re.sub("\D", "", totalCount)
totalCount = re.sub("\D", "", totalCount)
import re
totalCount = re.sub("\D", "", totalCount)
print(totalCount)
totalCount = '100abc1'
totalCount = re.sub("\D", "", totalCount)
print(totalCount)
import nltk
wsj = nltk.corpus.treebank.tagged_words(simplify_tags=True)
wsj = nltk.corpus.treebank.tagged_words()
print(wsj)
word_tag_fd=nltk.FreqDist(wsj)
print(word_tag_fd)
[word + "/" + tag for (word, tag) in word_tag_fd if tag.startswith('V')]
print(word_tag_fd)
print(word_tag_fd[:10])
list(word_tag_fd)
import nltk
brown_learned_text = nltk.corpus.brown.words(categories='learned')
sorted(set(b for (a, b) in nltk.ibigrams(brown_learned_text) if a == 'often'))
sorted(set(b for (a, b) in nltk.bigrams(brown_learned_text) if a == 'often'))
frequency = nltk.defaultdict(int)
words = nltk.corpus.words.words('en')
anagrams = nltk.defaultdict(list)
for word in words:
key = ''.join(sorted(word))
for word in words:
key = ''.join(sorted(word))
for word in words:
''.join(sorted(word))
